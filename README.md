# ZIP-DL

This repository contains the code for the paper "Low-Cost Privacy-Aware Decentralized learning", available here: https://arxiv.org/abs/2403.11795

Some code fragments were ommitted as they are too dependent of our original computing grid, and use [enoslib](https://discovery.gitlabpages.inria.fr/enoslib/) scripts. They are all related to deploying and then saving simulations results, which is built on top of our `decentralizepy` fork.

## Organization of the repository:
* Simulation is performed using the code of the `decentralizepy` submodule.
* Privacy attacks are realized in the `attack/` folder of this repository.
* Code about reorganizing the data from the `decentralizepy` simulation as well as launching all experiments was omitted, since it relies too heavily on our computing architecture ([Grid5000](https://www.grid5000.fr/w/Grid5000:Home)). The full code is nevertheless available [here](https://gitlab.inria.fr/dilereve/decentralizepy_grid5000).
* Singularity images, one used to [run simulations](compute_container.def) and one to [run attacks](attacker_container.def). The [Makefile](Makefile) is used to build those containers.
* Some auxiliary code, used for other types of simulation, are available under `misc_simulations/`. In particular, it is the code used for Figure 13 and Figure 14, and can be run independently.


The typical order of operation is the following:
1) Simulate ZIP-DL, where the attacker(s) will save models to then perform an attack, using the `decentralizepy` library. To run a simulation, one must generate the desired configuration file, split it across all the machines with the `ip.json` file correctly set, 
2) Once the simulation is done, organize the result and store them in a single folder if the simulation was decentralized accross multiple machines.
3) Run attacks, using the `attacker_container` and the `attacks` folder.


## Installation
You can run `make` to build the Singularity images that contains all the necessary libraries.

For development purposes (such as language servers) or to run locally, you may want to create a local environment. 
First, create a virtual environment. We only tested installation with python 3.10, note that python 3.11 may yield to installation conflicts with `sklearn`.

```
python3.10 -m venv venv-zip-dl
source venv-*/bin/activate
```

Then, install requirements for `decentralizepy`:

```
pip install --editable decentralizepy
```

Finally, install the requirements for this repository:

```
pip install -r requirements.txt
```

# Experimental pipeline overview
We describe the typical simulation pipeline we used to produce the results in our paper. It mainly runs in 4 steps:
1) Simulating a decentralized learning scenario
2) Reorganizing the simulation results under a specific structure.
3) Running attacks on the simulation result.
4) Running visualization scripts on the resulting data.

We detail below each of these individual steps, and link to the relevant code that is important to our paper.

## 1 - Running simulations

Simulations need to be run using [decentralizepy](https://github.com/sacs-epfl/decentralizepy). The first step run our simulation is thus to be able to deploy the library on a computing grid.

Our fork mainly implements two additions:
* We add the [`ZIP-DL`](decentralizepy/src/decentralizepy/sharing/ZeroSumSharing.py) (also named zerosum in the code) and baseline [`Muffliato`](decentralizepy/src/decentralizepy/sharing/Muffliato.py) as `Sharing` objects.
* We adapt the simulation scripts to save models at a given interval (given in the configuration file). Those saved models will then be used for downstream attacks. 

To run simulations, one first needs to generate a configuration file with the appropriate configurations, and then deploy 

## 2 - Saving simulations results structure
How you need to reorganize the result of the `decentralizepy` simulation in order to launch attacks.

Here is what is expected to be saved in an experiment:
```
experiment_name/
    config.ini
    g5k_config.json
    machine1/
    ...
    machinek/
```
For more details:
* The `machine*` folders are automatically generated by the `decentralizepy` simulation, but must be put together in a single folder.
* The `config.ini` is the `decentralizepy` config file, that was used to run the simulation. 
* The `g5k_config.json` file contains the remaining information about the simulation (information that is mostly passed as argument to the `decentralizepy` simulation, and thus was not fitting for the simulation configuration file). In particular, it should contain:
    * The number of nodes in the simulation
We provide some e

## 3 - Attacking simulation results

Attack can be performed using the `attacker_container.sif` container. It is otherwise just a wrapper to [`perform_attacks.py`](attacks/perform_attacks.py), that will launch the attacks on the models saved during the simulation.

When using the container, one must bind the folder containing the experiments to attack to `/experiments_to_attack` in the container, and give the arguments expected by [`perform_attacks.py`](attacks/perform_attacks.py).

The structure of `attacks/` is the following:
* [`perform_attacks.py`](attacks/perform_attacks.py) launches all the attack on a given folder, automatically fetching the necessary 
* [`classifier_attacker.py`](attacks/classifier_attacker.py) 


## 4 - Visualizing results and storing data


---

# Artifact Appendix

Paper title: **Low-Cost Privacy-Preserving Decentralized Learning**

Artifacts HotCRP Id: **9** (not your paper Id, but the artifacts id)

Requested Badge: **Available**

## Description
This artifact contains the code for simulations of the paper **Low-Cost Privacy-Preserving Decentralized Learning**. In particular, it contains the necessary code to:
* Run simulations corresponding to our algorithm
* Perform the attacks we use in our paper.
* Gather and aggregate the results to generate the data used in our paper.

Some chosen important code fragments for the paper are:
* Implementation of [algorithm 1](https://github.com/dimiarbre/decentralizepy/blob/main/src/decentralizepy/sharing/ZeroSumSharing.py#L16)
* 

### Security/Privacy Issues and Ethical Concerns (All badges)
This artifact does not hold any security or privacy risk. We use public datasets, and perform privacy attacks on models generated within our experiments.


## Environment 
In the following, describe how to access our artifact and all related and necessary data and software components.
Afterward, describe how to set up everything and how to verify that everything is set up correctly.

### Accessibility (All badges)
This artifact itself contains most of the source code, limited to what was used in the paper. As described above in this README, the full source code can nevertheless be found [at this link](https://gitlab.inria.fr/dilereve/decentralizepy_grid5000/-/tree/Popets_revision?ref_type=tags). However, this repository aims to be self-sufficient in terms of source code, with the only code missing being the experiment configuration generation and deployment scripts.

For the detailed organization of this repository, we refer to the above sections that describes the aim of each folder or code fragment.
